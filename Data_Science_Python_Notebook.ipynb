{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science: Analysis, Visualization, and Machine Learning with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## by Troy Nguyen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook showcases the Data Science skills that I've enhanced with the help of IBM's Cognitive Classes, from which I earned badges in: [Applied Data Science with Python](https://www.youracclaim.com/badges/7921c193-b25b-4395-bdf4-caaef5164e80/linked_in_profile), and [Machine Learning with Python]().  \n",
    "The workflow processes and examples in this notebook are accurate to the style that I implement in a professional setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "- [Data Analysis](#Data-Analysis:-The-Price-of-Cars)\n",
    "    - [Data Import](#Data-Import)\n",
    "    - [Data Wrangling](#Data-Wrangling)\n",
    "        - [Invalid Missing Values](#Convert-Invalid-Missing-Values)\n",
    "        - [Replacing and Dropping Missing Values](#Replacing-and-Dropping-Missing-Values)\n",
    "        - [Correcting Data Types](#Correcting-Data-Types)\n",
    "        - [Data Standardization](#Data-Standardization)\n",
    "        - [Data Normalization](#Data-Normalization)\n",
    "        - [Data Binning](#test)\n",
    "        - [Dummy Variables](#Dummy-Variables)\n",
    "    - [Exploratory Data Analysis](#test)\n",
    "    - [Model Development](#test)\n",
    "    - [Model Evaluation](#test)\n",
    "    \n",
    "    \n",
    "- [Data Visualization](#test)\n",
    "    - [Sub-heading](#test)\n",
    "    \n",
    "    \n",
    "- [Machine Learning](#test)\n",
    "    - [Sub-heading](#test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis: The Price of Cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Data Analysis, we can figure out the max price a car can be realistically sold for.  \n",
    "We will be using a public dataset named **\"1985 Auto Imports Database\"**, provided by Jeffrey C. Schlimmer.  \n",
    "The dataset can be found at https://archive.ics.uci.edu/ml/machine-learning-databases/autos, as filename: **\"import-85.data\"**.\n",
    "\n",
    "Below is a sample of the dataset viewed in a text editor:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test_title1](Picture_of_Cars_Dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this dataset is structured in CSV format, comma-separated values.  \n",
    "Each row represents a new observation, while each comma separates one column (or variable) from the next.\n",
    "\n",
    "There is also another helpful file in the open directory named **\"import-85.names\"**, which contains further details about the dataset.  \n",
    "IBM Cognitive Class was kind enough to compile the column header info into a more digestable format as can be seen here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test_title2](Picture_of_Cars_Names.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2 columns that the **\"import-85.names\"** file brings special attention to (besides the very important **price** column in No. 26), are No. 1 and 2: **symboling** and **normalized-losses**.\n",
    "\n",
    "**Symboling:** \n",
    "**The degree to which the auto is more risky than its price indicates.**   \n",
    "Cars are initially assigned a risk factor symbol associated with its price.\n",
    "Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale.  \n",
    "Actuarians call this process \"symboling\". A value of +3 indicates that the auto is risky, -3 that it is probably pretty safe.\n",
    "\n",
    "**Normalized-losses:**\n",
    "**The relative average loss payment per insured vehicle year.**   \n",
    "This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality, etc...), and represents the average loss per car per year.\n",
    "\n",
    "Key points we've seen so far is:  \n",
    "\n",
    "1. Our data is in **CSV format** \n",
    "2. Our dataset **does not have headers/column names**, but the supporting **\"import-85.names\"** file does\n",
    "3. Our dataset contains questions marks: **\"?\"** which stands for **missing values** (as informed in the names file), we will deal with these in a later section\n",
    "\n",
    "Now that we have a basic understanding of our data, we are ready to import our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import the data using the **Pandas Library**, which offers data structure and tools for effective data manipulation and analysis.  \n",
    "We will do this in 5 steps:\n",
    "1. Import the **Pandas Library**\n",
    "2. Create a **filepath variable** to hold our data source location\n",
    "3. Use the **pandas.read_csv method** to import our data in a dataframe\n",
    "4. Create a list that holds the column headers (since the actual dataset lacks headers)\n",
    "5. Join the headers to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filepath='imports-85.data'\n",
    "df=pd.read_csv(filepath, header=None) # header=None specifies that there is no header in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers=[\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\",\"num-of-doors\",\"body-style\",\"drive-wheels\",\n",
    "         \"engine-location\",\"wheel-base\",\"length\",\"width\",\"height\",\"curb-weight\",\"engine-type\",\"num-of-cylinders\",\"engine-size\",\n",
    "         \"fuel-system\",\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing a dataset, it's good practice to print a sample to make sure nothing went wrong.  \n",
    "In most cases, using the **pandas.dataframe.head() method** to show the first n rows is a sufficient check.  \n",
    "Let's check the first few rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symboling</th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>make</th>\n",
       "      <th>fuel-type</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>num-of-doors</th>\n",
       "      <th>body-style</th>\n",
       "      <th>drive-wheels</th>\n",
       "      <th>engine-location</th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>...</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>fuel-system</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>?</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>?</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>...</td>\n",
       "      <td>152</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>164</td>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.8</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102</td>\n",
       "      <td>5500</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>164</td>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>4wd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.4</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   symboling normalized-losses         make fuel-type aspiration num-of-doors  \\\n",
       "0          3                 ?  alfa-romero       gas        std          two   \n",
       "1          3                 ?  alfa-romero       gas        std          two   \n",
       "2          1                 ?  alfa-romero       gas        std          two   \n",
       "3          2               164         audi       gas        std         four   \n",
       "4          2               164         audi       gas        std         four   \n",
       "\n",
       "    body-style drive-wheels engine-location  wheel-base  ...  engine-size  \\\n",
       "0  convertible          rwd           front        88.6  ...          130   \n",
       "1  convertible          rwd           front        88.6  ...          130   \n",
       "2    hatchback          rwd           front        94.5  ...          152   \n",
       "3        sedan          fwd           front        99.8  ...          109   \n",
       "4        sedan          4wd           front        99.4  ...          136   \n",
       "\n",
       "   fuel-system  bore  stroke compression-ratio horsepower  peak-rpm city-mpg  \\\n",
       "0         mpfi  3.47    2.68               9.0        111      5000       21   \n",
       "1         mpfi  3.47    2.68               9.0        111      5000       21   \n",
       "2         mpfi  2.68    3.47               9.0        154      5000       19   \n",
       "3         mpfi  3.19    3.40              10.0        102      5500       24   \n",
       "4         mpfi  3.19    3.40               8.0        115      5500       18   \n",
       "\n",
       "  highway-mpg  price  \n",
       "0          27  13495  \n",
       "1          27  16500  \n",
       "2          26  16500  \n",
       "3          30  13950  \n",
       "4          22  17450  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully imported our data with the proper headers, and can move on to wrangling our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can do actual analysis on our data, we have to make sure that our data is properly wrangled, or pre-processed.  \n",
    "For example, the dataset could have missing values, incorrect data types, misformatted data, and so forth.  \n",
    "Let's start with handling missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Invalid Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset has \"invalid\" missing values in the form of question marks, **\"?\"**.  \n",
    "We want to replace **\"?\"** with **NaN (Not a Number)**, which is Python's default missing value marker for reasons of computational speed and convenience.  \n",
    "We can use the **pandas.dataframe.replace method** and **numpy.nan constant** to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df.replace(\"?\", np.nan, inplace = True) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the missing values in a compatible format, we can look at how many we have and where.  \n",
    "Let's use the built-in Python function **isnull()**, combined with a **for loop** to count missing values per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = df.isnull()                          # create a dataframe of the missing values\n",
    "\n",
    "for column in missing_data.columns.values.tolist():\n",
    "    print(column)\n",
    "    print (missing_data[column].value_counts())\n",
    "    print(\"\")                                       # adds an extra line between variables for easier reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 7 columns with missing data:  \n",
    "\n",
    "1. \"normalized-losses\": 41 missing values\n",
    "2. \"num-of-doors\": 2 missing values\n",
    "3. \"bore\": 4 missing values\n",
    "4. \"stroke\" : 4 missing values\n",
    "5. \"horsepower\": 2 missing values\n",
    "6. \"peak-rpm\": 2 missing values\n",
    "7. \"price\": 4 missing values\n",
    "\n",
    "**Note**: (The **\"import-85.names\"** file actually provides to us the missing values info that we just calculated.  \n",
    "However, we are not always lucky to have that info and must know how to find the missing values ourselves.  \n",
    "In addition, even if you are given a nice file like such, you still want to check your findings compared to the document.)\n",
    "\n",
    "Now that we know what we're up against, let's take a look at how to deal with the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing and Dropping Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to deal with missing values, which include:\n",
    "\n",
    "1. Replace the missing data with the average or most common value of the variable\n",
    "2. Remove the whole row with the missing value (if the column is our main focus or if not many observations are missing values)\n",
    "3. Remove the whole column with the missing value (only if most entries in the column are empty)\n",
    "\n",
    "We will perform all methods above except for 3: \"Remove whole column\", since we do not have a column with a large amount of values missing (the biggest being 41 out of 205 rows for \"normalized-losses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Missing Values - Replacing Missing Continuous Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to replace missing values in our **\"normalized-losses\"** column (with the average), we first calculate what the average is.  \n",
    "Once we have the average stored in a variable, we can replace every missing value with it.  \n",
    "Let's perform this method to all continuous variables that need fixing (with the exception of price, as that is our dependent variable that we will drop rows for later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalized losses\n",
    "avg_norm_loss = df[\"normalized-losses\"].astype(\"float\").mean(axis=0)  # calculate column as float to avoid possible data type errors\n",
    "print(\"Average of normalized-losses:\", avg_norm_loss)                 # show the average that we will use to replace\n",
    "df[\"normalized-losses\"].replace(np.nan, avg_norm_loss, inplace=True)  # replace missing values with the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bore\n",
    "avg_bore = df[\"bore\"].astype(\"float\").mean(axis=0)\n",
    "print(\"Average of bore:\", avg_bore)\n",
    "df[\"bore\"].replace(np.nan, avg_bore, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stroke\n",
    "avg_stroke = df[\"stroke\"].astype(\"float\").mean(axis=0)\n",
    "print(\"Average of stroke:\", avg_stroke)\n",
    "df[\"stroke\"].replace(np.nan, avg_stroke, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#horsepower\n",
    "avg_horsepower = df[\"horsepower\"].astype(\"float\").mean(axis=0)\n",
    "print(\"Average of horsepower:\", avg_horsepower)\n",
    "df[\"horsepower\"].replace(np.nan, avg_horsepower, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#peak-rpm\n",
    "avg_peak_rpm = df[\"peak-rpm\"].astype(\"float\").mean(axis=0)\n",
    "print(\"Average of peak-rpm:\", avg_peak_rpm)\n",
    "df[\"peak-rpm\"].replace(np.nan, avg_peak_rpm, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Missing Values - Replacing Missing Categorical Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing missing categorical values is very similar to replacing continuous ones, with the main difference being we use the most commonly occuring value, rather than the calculated \n",
    "mean.  \n",
    "Our only categorical variable to fix is **\"num-of-doors\"** and we can use the **idxmax method** to calculate the most common value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_doors=df['num-of-doors'].value_counts().idxmax()         # create variable to hold the most common value\n",
    "print(mode_doors)                                             # print the common value\n",
    "df[\"num-of-doors\"].replace(np.nan, mode_doors, inplace=True)  # replace the missing values with the most common value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Missing Values - Dropping Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our analysis is focusing on the column **\"price\"**, we will drop rows that are missing a price value.  \n",
    "We can use the **pandas.dropna method** to drop rows that contain missing values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"price\"], axis=0, inplace=True)  # axis=0 specifies rows, inplace=True modifies the dataset\n",
    "df.reset_index(drop=True, inplace=True)            # we reset the index since we dropped rows of data\n",
    "df.head()                                          # reprint the dataset to check what we have done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas automatically assigns data types based on the encoding it detects from the original data table.  \n",
    "For a number of reasons, this assignment may not always be correct and could cause problems.  \n",
    "For example: if you wanted to perform a math function (like sum or divide) on a column like **\"horsepower\"** but it was accidently assigned as an **object** instead of **integer or float**, then it would not be possible.  \n",
    "We can apply the **dtype** method to return the data type of each column and see if something is not as we expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we read down the output, most of the data types make sense, however some do not.  \n",
    "These include: **\"normalized-losses\", \"bore\", \"stroke\", \"horsepower\", \"peak-rpm\", and \"price\"**, as these are **continuous** variables assigned as **objects**.  \n",
    "\n",
    "Let's go ahead and use the **dataframe.astype() method** to convert the datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"normalized-losses\"]=df[\"normalized-losses\"].astype(\"int64\")\n",
    "df[\"bore\"]=df[\"bore\"].astype(\"float\")                            # converted to float since we noticed decimal values\n",
    "df[\"stroke\"]=df[\"stroke\"].astype(\"float\")                        # converted to float since we noticed decimal values\n",
    "df[\"horsepower\"]=df[\"horsepower\"].astype(\"int64\")\n",
    "df[\"peak-rpm\"]=df[\"peak-rpm\"].astype(\"int64\")\n",
    "df[\"price\"]=df[\"price\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization is the process of transforming data into a different and/or common format.  \n",
    "Though we are lucky that our data is in **mpg (miles per gallon) format**, sometimes we may not be so lucky and need to convert formats to fit the business needs.  \n",
    "For instance if we were doing this analysis in a country that uses the **L/100km standard**, we will have to do some extra work.  \n",
    "Let's create new columns for city-mpg and highway-mpg, named **city-L/100km** and **highway-L/100km**.\n",
    "\n",
    "The formula for this unit conversion is: **L/100km = 235 / mpg**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['city-L/100km'] = 235/df[\"city-mpg\"]        # create a new column off a transformation of an existing one\n",
    "df['highway-L/100km'] = 235/df[\"highway-mpg\"]  # do the same for highway-mpg\n",
    "df.head()                                      # check the new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Normalization is the process of transforming variable ranges to be more consistent/closer together.  \n",
    "Large differences in variable ranges (such as Age range: 1-100 and Income range: 1-500000), can create large intrinsic differences in impact.  \n",
    "(Example: Even if income has the same or less true impact than age, the model will naturally say that income has more impact as it changes.)  \n",
    "We can avoid this by using Data Normalization, specifically **Simple Feature Scaling: normalizing the ranges to be from 0 to 1**.  \n",
    "We can do this by dividing original values by their maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize length, width, and height\n",
    "df['length'] = df['length']/df['length'].max()\n",
    "df['width'] = df['width']/df['width'].max()\n",
    "df['height'] = df['height']/df['height'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Binning (or rather not?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One technique that was taught in the courses was Data Binning, that is the process of grouping continuous variable values into smaller bins.  \n",
    "So instead of treating something like \"age\" as a regular continuous value that ranges from 1-100 with many different unique values, you could group the ages into categorical sets such as 1-33 (young), 34-66 (average), and 67-100 (old). However as of this moment I do not see many good reasons to perform data binning, as it can often reduce analysis strength. One article that perfectly puts into words some arguments against data binning, is \"Why binning continuous data is almost always a mistake\" by Peter Flom, which can be found [here](https://medium.com/@peterflom/why-binning-continuous-data-is-almost-always-a-mistake-ad0b3a1d141f).\n",
    "\n",
    "To summarize:\n",
    "\n",
    "1. Data Binning creates the illusion that **\"something huge happens at the cutoff\"**, like my example above: a 1 year old and 33 year old are similar but a 33 year old and 34 year old are very different\n",
    "2. Data Binning increases type I (false positive) and type II (false negative) error\n",
    "3. Data Binning (though rare) can be good for situations where treatment is truly dichotomous and/or there is a really large gap (legal vs illegal drinkers, legal drinking age cutoff)\n",
    "\n",
    "I would still love to return to this topic in the future and gain a better understanding of its strengths and weaknesses, but at the moment have no desire to use this technique for my data science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can assign numbers to Categorical Variable values so that they can be used in Regression Analysis later on (most statistical models require numbers as input).  \n",
    "This is easiest and most effective for variables that have at most 2 unique values (but more works as well), such as these from our dataset:  \n",
    "* fuel-type: gas, diesel.\n",
    "* aspiration: std, turbo.\n",
    "* num-of-doors: four, two.\n",
    "* engine-location: front, rear.\n",
    "\n",
    "However for demonstration and time's sake, I will only be creating dummy variables for fuel-type.  \n",
    "We can use the **pandas.getdummies method** to assign numerical values to \"gas\" and \"diesel\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_fuel_df = pd.get_dummies(df[\"fuel-type\"])\n",
    "dummy_fuel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the dummy variables for clarity\n",
    "dummy_fuel_df.rename(columns={'diesel':'diesel-flag','gas':'gas-flag'}, inplace=True)\n",
    "dummy_fuel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the main dataset with the fuel-type dataframe we just made\n",
    "df = pd.concat([df, dummy_fuel_df], axis=1)\n",
    "\n",
    "# Drop original \"fuel-type\" column from main dataset\n",
    "df.drop(\"fuel-type\", axis = 1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start off our exploratory data analysis by using the **pandas.describe() method** to analyze the continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>make</th>\n",
       "      <th>fuel-type</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>num-of-doors</th>\n",
       "      <th>body-style</th>\n",
       "      <th>drive-wheels</th>\n",
       "      <th>engine-location</th>\n",
       "      <th>engine-type</th>\n",
       "      <th>num-of-cylinders</th>\n",
       "      <th>fuel-system</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>52</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>?</td>\n",
       "      <td>toyota</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.40</td>\n",
       "      <td>68</td>\n",
       "      <td>5500</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>41</td>\n",
       "      <td>32</td>\n",
       "      <td>185</td>\n",
       "      <td>168</td>\n",
       "      <td>114</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>202</td>\n",
       "      <td>148</td>\n",
       "      <td>159</td>\n",
       "      <td>94</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       normalized-losses    make fuel-type aspiration num-of-doors body-style  \\\n",
       "count                205     205       205        205          205        205   \n",
       "unique                52      22         2          2            3          5   \n",
       "top                    ?  toyota       gas        std         four      sedan   \n",
       "freq                  41      32       185        168          114         96   \n",
       "\n",
       "       drive-wheels engine-location engine-type num-of-cylinders fuel-system  \\\n",
       "count           205             205         205              205         205   \n",
       "unique            3               2           7                7           8   \n",
       "top             fwd           front         ohc             four        mpfi   \n",
       "freq            120             202         148              159          94   \n",
       "\n",
       "        bore stroke horsepower peak-rpm price  \n",
       "count    205    205        205      205   205  \n",
       "unique    39     37         60       24   187  \n",
       "top     3.62   3.40         68     5500     ?  \n",
       "freq      23     20         19       37     4  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=['object'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
